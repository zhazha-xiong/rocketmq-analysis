# 开源软件基础大作业：Apache RocketMQ 仓库分析方案

> Author：渣渣熊
> Date：2026/01/11

---

## 一、需求分析

### 1.1 项目介绍

以 Apache RocketMQ 及其核心子项目为分析对象，综合运用**静态代码分析、版本历史挖掘**和**社区规范评估**等方法，从代码质量、研发效能和社区健康度等维度，对该项目进行一次系统性的分析。

### 1.2 研究目标

本项目设定四大核心研究模块，前三个模块分别从代码质量、研发效能与工程治理三个层面开展分析，第四个模块负责自动化汇总与智能化解读。

1.  **模块 A：代码质量与潜在风险（Python 客户端）**
    *   **核心问题**：RocketMQ 相关 Python 客户端代码质量如何？是否存在常见的潜在安全漏洞或维护性风险？
    *   **目标**：通过静态分析工具，量化评估 `apache/rocketmq-client-python` 与 `apache/rocketmq-clients` 的复杂度与安全风险。
    *   **交付物**：代码复杂度/漏洞统计图表 + Markdown 格式的质量分析报告。

2.  **模块 B：研发效能与工作节律（提交历史）**
    *   **核心问题**：RocketMQ 核心贡献者的工作模式是怎样的？社区是否存在普遍的“加班”现象？其迭代节奏有何特点？
    *   **目标**：基于 Git 提交历史，对开发者的**工作时段、提交频率、协作强度**进行数据建模。
    *   **交付物**：工作节律/贡献分布图表 + Markdown 格式的效能洞察报告。

3.  **模块 C：工程实践与社区规范性（治理与工程化）**
    *   **核心问题**：作为一个 Apache 顶级项目，RocketMQ 的工程化与社区治理水平如何？
    *   **目标**：建立覆盖版本控制、持续集成、文档治理的**规范性评估模型**，进行综合打分。
    *   **交付物**：雷达图/能力分布图 + Markdown 格式的规范性评估报告。

4.  **模块 D：智能化归纳与综合汇报（统一入口与汇总）**
    *   **核心问题**：如何将上述分散的工程数据与图表整合成一份具备业务洞察力的完整报告？
    *   **目标**：构建统一的脚本启动入口，串行驱动模块 A/B/C 运行，收集所有模块的交付物（图表 + Markdown），利用**多模态大模型**进行综合分析，生成最终的一体化汇报文档。
    *   **输入**：模块 A/B/C 的中间数据、可视化图表、子报告。
    *   **输出**：一份结构完善的 `FINAL_REPORT.md`，包含分析方法、关键数据展示、AI 分析与改进建议。

### 1.3 分析对象

本项目将重点分析以下 Apache RocketMQ 的核心 GitHub 仓库：

-   **主仓库 (`apache/rocketmq`)**: 项目核心代码库，主要由 Java 实现，是分析社区整体活跃度与治理规范的核心数据源。
    - 链接: [https://github.com/apache/rocketmq](https://github.com/apache/rocketmq)
-   **官方 Python 客户端 (`apache/rocketmq-client-python`)**: 基于 C++ 客户端封装的 Python SDK，是静态分析的主要对象之一。
    - 链接: [https://github.com/apache/rocketmq-client-python](https://github.com/apache/rocketmq-client-python)
-   **新一代多语言客户端 (`apache/rocketmq-clients`)**: 基于 gRPC 的新一代客户端集合，其 Python 实现同样是静态分析的主要对象之一。
    - 链接: [https://github.com/apache/rocketmq-clients](https://github.com/apache/rocketmq-clients)

## 2. 总体方案设计

### 2.1 整体架构与技术栈

本方案采用模块化、流水线式的架构设计。所有分析任务将通过 Python 脚本实现自动化，并通过统一的入口进行调度。数据处理流程严格遵循**数据采集 -> 数据清洗与预处理 -> 分析与建模 -> 结果呈现与报告**的原则。所有数据和图表持久化存储，以支持可复现与最终的 LLM 综合分析。

*   **技术栈**：
    *   **语言**：Python 3.10+
    *   **核心库**：
        *   数据处理：`pandas`, `numpy`
        *   网络请求：`requests`
        *   环境管理：`python-dotenv`
        *   可视化：`matplotlib`, `seaborn`
        *   静态分析：`bandit`, `lizard`
        *   时间计算：`chinesecalendar` 

### 2.2 模块 A 设计：Python 静态分析

#### 2.2.1 数据采集与工具

-   **数据源**: `apache/rocketmq-client-python` 和 `apache/rocketmq-clients` 仓库的 Python 源代码（`.py` 文件）。
-   **工具栈建议**:
    -   **主选**:
        -   **Bandit**: 用于 **发现常见安全漏洞**。它通过构建抽象语法树（AST）并应用规则集来扫描代码，能有效识别硬编码密码、不安全的反序列化等问题。
        -   **Lizard**: 用于 **度量代码复杂度**，提供圈复杂度、代码行数 (NLOC)、函数参数数量等关键指标，帮助定位难以维护的代码。
    -   **备选/进阶**:
        -   **`ast`/`libcst`**: 若需进行更细致的、自定义的静态分析（例如，检查特定函数调用规范），可使用 Python 内置的 `ast` 模块或功能更强大的 `libcst` 库**自行编写检查器**。

#### 2.2.2 关键指标与判定标准

-   **潜在漏洞类别 (基于 Bandit)**:
    -   我们将重点关注 Bandit 报告中的 **`High` 和 `Medium` 严重性 (Severity) 及置信度 (Confidence) 的问题**。
    -   漏洞将按类型（如 `B101: assert_used`, `B404: import_subprocess`）进行分类统计。
-   **代码复杂度指标 (基于 Lizard)**:
    -   **高圈复杂度**: 函数圈复杂度 (Cyclomatic Complexity) > **15**。
    -   **过长函数**: 函数代码行数 (NLOC) > **80**。
    -   **过多参数**: 函数参数数量 > **5**。
-   **误报处理**:
    -   对于 Bandit 报告的潜在误报，我们将通过**人工抽样审查**的方式进行确认。在报告中将明确记录误报的比例和典型案例，但**不会修改上游仓库代码**（例如，通过加 `# nosec` 来抑制告警）。
### 2.3 模块 B 设计：Git 提交历史分析

#### 2.3.1 数据采集与清洗

-   **数据源**: `apache/rocketmq` 等核心仓库的 `git log`。
-   **采集内容**: 提交哈希 (hash), 作者名 (author name), 作者邮箱 (author email), **作者提交日期 (author date)**。
-   **清洗流程**:
    1.  **解析日志**: 使用 `GitPython` 或 `git log` 命令的格式化输出，将提交记录解析为结构化数据（如 CSV 或 Pandas DataFrame）。
    2.  **时区统一**: 将所有 `author date` 统一转换为 **UTC+8 (北京时间)**，以进行统一的工作时段分析。
    3.  **机器人提交排除**: **过滤**掉作者名或邮箱中包含 `bot`、`action`、`gitter` 等关键词的提交，排除自动化脚本的干扰。
    4.  **合并提交排除**: **过滤**掉 `Merge` 提交，因为其提交时间戳不反映实际的编码工作。

#### 2.3.2 “加班”与工作节律定义

-   **工作日**: 周一至周五。
-   **核心工作时段**: 定义为工作日的 **上午 10:00 至晚上 19:00**。
-   **“加班”时段**:
    -   **工作日非核心时段**: 工作日的 `00:00 - 10:00` 及 `19:00 - 24:00`。
    -   **周末**: 周六、周日全天。
-   **关键指标**:
    -   按“小时/天”和“星期/天”聚合的提交次数。
    -   核心工作时段与加班时段的提交次数及占比。
    -   不同贡献者的“加班”提交次数排名。

### 2.4 模块 C 设计：仓库规范性评估

#### 2.4.1 评估维度与权重方案

我们将设计一个包含五大维度的量化评估模型，总分 100 分。

| **评估维度**         | **评估子项**             | **数据来源**                                | **评估标准与判定方法**                                                                      | **权重** |
| -------------------- | ------------------------ | ------------------------------------------- | ------------------------------------------------------------------------------------------- | -------- |
| **版本控制 (25分)**  | **提交信息规范性**       | `git log`                                   | **检查 Commit Message 是否遵循特定格式** (如 Conventional Commits: `feat:`, `fix:`)。通过正则表达式匹配评分。 | 15       |
|                      | **分支与 PR 流程**         | `CONTRIBUTING.md`, GitHub API               | 检查文档中是否定义了分支策略；通过 API 抽样 PR，评估 Code Review 和 Issue 关联情况。      | 10       |
| **持续集成 (20分)**  | **CI/CD 配置与覆盖**     | `.github/workflows/`                        | 检查是否存在 CI 配置文件，是否覆盖了**构建、测试**等关键阶段。                          | 10       |
|                      | **CI 运行健康度**        | GitHub Actions API                          | 统计近期（如过去30天）主干分支上 CI pipeline 的**运行成功率**。                         | 10       |
| **社区治理与文档 (25分)** | **治理文档完备性**       | 仓库根目录                                  | **检查 `LICENSE`, `CONTRIBUTING.md`, `CODE_OF_CONDUCT.md` 文件是否存在且内容充实**。    | 15       |
|                      | **发布节奏**             | GitHub Releases/Tags API                    | 分析项目发布（Release/Tag）的**频率、规律性及是否遵循语义化版本规范**。                 | 10       |
| **代码质量与测试 (30分)** | **测试覆盖**             | `pom.xml` (Java), CI 日志, 文件结构         | 检查构建配置或 CI 日志中是否声明测试覆盖率工具 (如 JaCoCo)；若无，则评估**测试文件与源码文件的比例**。 | 15       |
|                      | **编码规范一致性**       | `.editorconfig`, Linter 配置文件, 模块A结果 | 检查是否存在编码风格配置文件；结合模块 A 的静态分析结果，评估代码规范的实际执行情况。   | 15       |

### 2.5 模块 D 设计：智能化汇总 

#### 2.5.1 提供统一运行入口

为ABC三个模块提供统一的入口，通过依次调用ABC三个模块的`main.py`文件生成每个模块的数据、图表与初步报告。需要确保各个模块正确运行，并且正确给出了交付物。如果有问题需要给出用户友好的警告。

#### 2.5.2 汇总报告

将三个模块的运行结果汇总，通过调用Qwen或者Seed等多模态大模型来生成完善的报告。需要给大模型交代清楚报告的要求，写入提示词。

### 2.6 工程化规范 (Engineering)

*   **目录结构**：
    ```text
    rocketmq-analysis
    ├── data
    │   ├── module_a
    │   ├── module_b
    │   └── module_c
    ├── figures
    │   ├── module_a
    │   ├── module_b
    │   └── module_c
    ├── scripts
    │   ├── module_a/
    │   ├── module_b/
    │   ├── module_c/
    │   └── module_d/ 
    └── docs/
    ```

## 3. 测试与验证策略 (Testing Strategy)

### 3.1 单元测试 (Unit Testing)
*   重点覆盖数据清洗逻辑（如邮箱脱敏、时间解析）。
*   覆盖评分算法（模块 C），确保 JSON 配置变更能正确反映在分数上。

### 3.2 有效性验证 (Validation)
*   **人工核查 (Human-in-the-loop)**:
    *   Randomly sample 5 Git commits to verify timestamp accuracy.
    *   **必须人工阅读** 模块 D 生成的 LLM 报告，确认：
        *   无幻觉 (Hallucination)：提到的数据必须在原始 CSV/JSON 中存在。
        *   逻辑自洽：给出的建议符合 RocketMQ 项目实际情况。

### 3.3 自动化 (Automation)
*   移除复杂的 CI Pipeline，改为**本地脚本化运行**。
*   通过 `run_analysis.bat` 或 `Makefile` 封装全流程。
